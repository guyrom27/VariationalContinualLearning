{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor()])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./mnist', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4691185c88>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    2     0     3     0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as plt\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "classes = [i for i in range(10)]\n",
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.distributions import Uniform\n",
    "\n",
    "class mlp_layer(nn.Module):\n",
    "    def __init__(self,d_in, d_out, activation):\n",
    "        \"\"\"\n",
    "        Activation is a function (eg. torch.nn.functional.sigmoid/relu)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.mu = nn.Linear(d_in, d_out)\n",
    "        self._init_weights(d_in, d_out)\n",
    "        self.activation = activation\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.activation(self.mu(x))\n",
    "\n",
    "    def _init_weights(self, input_size, output_size, constant=1.0):\n",
    "        scale = constant*np.sqrt(6.0/(input_size + output_size))\n",
    "        assert(output_size > 0)\n",
    "        nn.init.uniform_(self.mu.weight, -scale, scale)\n",
    "        nn.init.zeros_(self.mu.bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import Normal\n",
    "import copy\n",
    "\n",
    "\n",
    "class bayesian_mlp_layer(mlp_layer):\n",
    "    def __init__(self,d_in, d_out, activation):\n",
    "        \"\"\"\n",
    "        Activation is a function (eg. torch.nn.functional.sigmoid/relu)\n",
    "        \"\"\"\n",
    "        super().__init__(d_in,d_out,activation)\n",
    "        self.log_sigma = nn.Linear(d_in, d_out)\n",
    "        self.init_log_sigma()\n",
    "        #mu is initialized the same as non-Bayesian mlp\n",
    "        \n",
    "        \"\"\"\n",
    "        Attribute for now, but planning to do only \"in-place\" changes \n",
    "        \"\"\"\n",
    "        self.weight_sampler = Normal(self.mu.weight, \\\n",
    "                              torch.exp(self.log_sigma.weight))\n",
    "        self.bias_sampler = Normal(self.mu.bias, \\\n",
    "                              torch.exp(self.log_sigma.bias))\n",
    "        \n",
    "    def forward(self,x, sampling=True):\n",
    "        print(\"BMLP Sampling \" + str(sampling))\n",
    "        if sampling:\n",
    "            my_lin = nn.Linear(*self.mu.weight.shape)\n",
    "            my_lin.weight = nn.Parameter(self.weight_sampler.sample())\n",
    "            my_lin.bias = nn.Parameter(self.bias_sampler.sample())\n",
    "            return self.activation(my_lin(x))\n",
    "        else:\n",
    "            return super().forward(x)\n",
    "        \n",
    "        \n",
    "    def _init_log_sigma(self):\n",
    "        nn.init.constant_(self.log_sigma.weight, 0.0)\n",
    "        nn.init.constant_(self.log_sigma.bias, 0.0)\n",
    "    \n",
    "    def get_posterior(self):\n",
    "        return [(self.mu.weight, self.log_sigma.weight),(self.mu.bias, self.log_sigma.bias))\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalSamplingLayer:\n",
    "    def __init__(self,d_out):\n",
    "        self.d_out\n",
    "    \n",
    "    def __call__(self, mu_log_sigma_vec):\n",
    "        return Normal(mu_log_sigma_vec[:,:d_out], torch.exp(mu_log_sigma_vec[:,d_out:])).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "class FunctionComposition:\n",
    "    def __init__(self,f_list):\n",
    "        assert(len(f_list) > 0)\n",
    "        for i in range(len(f_list)-1):\n",
    "            assert(f_list[i].d_out == f_list[i].d_in)\n",
    "        self.f_list = f_list\n",
    "    \n",
    "    def __call__(self, x, *optional):\n",
    "        for f in self.f_list:\n",
    "            x = f(x,*optional)\n",
    "        return x\n",
    "\n",
    "    @property\n",
    "    def d_in(self):\n",
    "        return self.f_list[0].d_in\n",
    "    \n",
    "    @property\n",
    "    def d_out(self):\n",
    "        return self.f_list[-1].d_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "class BayesianNet(nn.Module, FunctionComposition):\n",
    "    def __init__(self,f_list):\n",
    "        super().__init__(f_list)\n",
    "    \n",
    "    def get_posterior(self):\n",
    "        return list(itertools.chain(*list(map(lambda f: f.get_posterior(), self.f_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNFactory:\n",
    "    @classmethod\n",
    "    def CreateNN(cls, dims, activations):\n",
    "        assert(len(dims)-1 == len(activations))\n",
    "        layers = []\n",
    "        for i in range(len(dims)-1):\n",
    "            layers.append(bayesian_mlp_layer(dims[i],dims[i+1],activations[i]))\n",
    "        return FunctionComposition(layers)\n",
    "    \n",
    "    @classmethod\n",
    "    def CreateBayesianNet(cls, dims, activations):\n",
    "        assert(len(dims)-1 == len(activations))\n",
    "        layers = []\n",
    "        for i in range(len(dims)-1):\n",
    "            layers.append(bayesian_mlp_layer(dims[i],dims[i+1],activations[i]))\n",
    "        return BayesianNet(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KL_div_gaussian(mu_q, log_sig_q, mu_p, log_sig_p): \n",
    "    \"\"\"\n",
    "    KL(q||p), gets log of sigma rather than sigma\n",
    "    \"\"\"\n",
    "    return log_sig_p - log_sig_q + (0.5)*torch.exp(-2*log_sig_p)*(torch.exp(log_sig_q)**2 + (mu_q - mu_p)**2)-1/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KL_div_gaussian_from_standard_normal(mu_q, log_sig_q):\n",
    "    #0,0 corresponds to N(0,1) due to the log_sig representation, works for multidim normal as well.\n",
    "    return KL_div_gaussian(mu_q, log_sig_q, 0.0, 0.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Zs_to_mu_sig(Zs):\n",
    "    dimZ = Zs.shape[1]//2 #1st is batch size 2nd is 2*dimZ\n",
    "    mu_qz = Zs_params[:,:dimZ]\n",
    "    log_sig_qz  = Zs_params[:,dimZ:]\n",
    "    return mu_qz, log_sig_qz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forced_interval = (1e-9, 1.0)\n",
    "def log_bernouillli(X, Mu_Reconstructed_X):\n",
    "    \"\"\"\n",
    "    Mu_Reconstructed_X is the output of the decoder. We accept fractions, and project them to the interval 'forced_interval' for numerical stability\n",
    "    \"\"\"\n",
    "    logprob =    x      * torch.log(torch.clamp(Mu_Reconstructed_X,         *forced_interval) \\\n",
    "              + (1 - x) * torch.log(torch.clamp((1.0 - Mu_Reconstructed_X), *forced_interval)\n",
    "    return torch.sum(logprob, dim=logprob.dim())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_P_y_GIVEN_x(Xs, enc, sample_and_decode, NumLogPSamples = 100):\n",
    "    \"\"\"\n",
    "    Returns logP(Y|X), KL(Z||Normal(0,1))\n",
    "    \"\"\"\n",
    "    Zs_params = enc(Xs)\n",
    "    mu_qz, log_sig_qz  = Zs_to_mu_sig(Zs)\n",
    "    kl_z = KL_div_gaussian_from_standard_normal(mu_qz, log_sig_qz)\n",
    "    logp = 0.0\n",
    "    for _ in range(NumLogPSamples):\n",
    "        #The Zs_params are the deterministic result of enc(Xs) so we don't recalculate them\n",
    "        Mu_Ys = sample_and_decode(Zs_params)\n",
    "        logp += log_bernouillli(x, Mu_Ys) / NumLogPSamples\n",
    "    return logp, kl_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SharedDecoder:\n",
    "    def __init__(self, dims, activations):\n",
    "        self.net = NNFactory.CreateBayesianNet(dims, activations)\n",
    "        self._init_prior()\n",
    "        \n",
    "    def __call__(self, Xs):\n",
    "        return self.net(Xs)\n",
    "    \n",
    "    def _init_prior(self):\n",
    "        \"\"\"\n",
    "        Initialize a constant tensor that corresponds to a prior distribution over all the weights\n",
    "        which is standard normal\n",
    "        \"\"\"\n",
    "        self.prior = [torch.zeros(x.shape) for x in self.net.get_posterior()]\n",
    "        \n",
    "    def update_prior(self):\n",
    "        \"\"\"\n",
    "        Copy the current posterior to a constant tensor, which will be used as prior for the next task\n",
    "        \"\"\"\n",
    "        self.prior = [x.clone.detach() for x in self.net.get_posterior()]\n",
    "        \n",
    "    def KL_from_prior(self):\n",
    "        return sum[KL_div_gaussian(*post, *prior) for (post, prior) in zip(self.net.get_posterior(), self.prior)]\n",
    "    \n",
    "    @property\n",
    "    def d_in(self):\n",
    "        return self.net.d_in\n",
    "    \n",
    "    @property\n",
    "    def d_out(self):\n",
    "        return self.net.d_out\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim \n",
    "\n",
    "#BayesianVAE\n",
    "class TaskModel(nn.Module):\n",
    "    def __init__(self, enc, dec_head, dec_shared, learning_rate = 1e-4):\n",
    "        self.enc = enc\n",
    "        self.dec_head = dec_head\n",
    "        self.dec_shared = dec_shared\n",
    "    \n",
    "        self.sampler = NormalSamplingLayer(self.dec_head.d_in)\n",
    "        self.sample_and_decode = FunctionComposition([self.sampler, self.dec_head, self.dec_shared])\n",
    " \n",
    "        #update just before training\n",
    "        self.DatasetSize = None\n",
    "        \n",
    "        #Guards from retraining- train only once\n",
    "        self.TrainGuard = True\n",
    "        \n",
    "        self.optimizer = self._create_optimizer(learning_rate)\n",
    "        return\n",
    "    \n",
    "    def forward(self, Xs):\n",
    "        logp, kl_z = log_P_y_GIVEN_x(Xs, self.enc, self.sample_and_decode)\n",
    "        kl_shared_dec_Qt_2_PREV_Qt = self.dec_shared.KL_from_prior()\n",
    "        #We ignore the kl(private dec || Normal(0,1) ) like the authors did\n",
    "        ELBO = torch.mean(logp) - torch.mean(kl_z) - (kl_shared_dec_Qt_2_PREV_Qt / self.DatasetSize)\n",
    "        return -ELBO\n",
    "    \n",
    "    def _create_optimizer(self, learning_rate):\n",
    "        return torch.optim.Adam(self.parameters(), lr=learning_rate)\n",
    "    \n",
    "    def _update_prior(self):\n",
    "        self.dec_shared.update_prior()\n",
    "        #no other priors should be updated. they are trained once.\n",
    "        return\n",
    "    \n",
    "    def train(self, n_epochs, task_trainloader):\n",
    "        #We don't intend a TaskModel to be trained more than once\n",
    "        assert(self.TrainGuard)\n",
    "        self.TrainGuard = False\n",
    "        \n",
    "        self.DatasetSize = len(task_trainloader.dataset)\n",
    "        #This will set the prior to the current posterior, before we start to change it during training\n",
    "        self._update_prior()\n",
    "        # loop over the dataset multiple times\n",
    "        for epoch in range(n_epochs):  \n",
    "            running_loss = 0.0\n",
    "            for i, data in enumerate(task_trainloader, 0):\n",
    "                # get the inputs\n",
    "                inputs, labels = data\n",
    "        \n",
    "                # step\n",
    "                self.optimizer.zero_grad()\n",
    "                loss = self(inputs)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "        \n",
    "                # print statistics\n",
    "                running_loss += loss.item() #?\n",
    "                if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                    print('[%d, %5d] loss: %.3f' %\n",
    "                          (epoch + 1, i + 1, running_loss / 2000))\n",
    "                    running_loss = 0.0\n",
    "        self.DatasetSize = None\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mnist_single_digit_loaders():\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimX=28*28\n",
    "dimH=500\n",
    "dimZ=50\n",
    "\n",
    "#Shared decoder\n",
    "dec_shared_dims=[dimH, dimH, dimX]\n",
    "dec_shared_activations=[F.relu,torch.sigmoid]\n",
    "\n",
    "#Encoder\n",
    "enc_dims=[dimX, dimH, dimH, dimZ*2]\n",
    "enc_activations=[F.relu,F.relu,lambda x:x]\n",
    "\n",
    "#Private decoder (Head)\n",
    "dec_head_dims=[dimZ, dimH, dimH]\n",
    "dec_head_activations=[F.relu,F.relu]\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    dec_shared = SharedDecoder(dec_shared_dims, dec_shared_activations) \n",
    "    \n",
    "    #TODO: check dec_shared.parameters()\n",
    "    \n",
    "    #this can be any iterable\n",
    "    task_loaders = create_mnist_single_digit_loaders()\n",
    "    \n",
    "    models = []\n",
    "    \n",
    "    #this may train the classifier to generate test_classifier\n",
    "    #evaluator = Evaluations()\n",
    "    \n",
    "    #A task corresponds to a digit\n",
    "    for task_id, loader in enumerate(task_loaders):\n",
    "        task_model = TaskModel(NNFactory.CreateNN(enc_dims, enc_activations), \\\n",
    "                               NNFactory.CreateNN(dec_head_dims,dec_head_activations), \\\n",
    "                               dec_shared)\n",
    "        models.append(task_model)\n",
    "        optimizer = create_optimizer(task_model.get_trainable_paramaters(), learning params)\n",
    "        task_model.train(n_epochs, loader, optimizer)\n",
    "        #make sure you don't change the model params inside the eval \n",
    "        #evaluator.create_task_evaluations(models)\n",
    "    \n",
    "    #evaluator.report_results()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "class A:\n",
    "    def __init__(self):\n",
    "        self.a = 3\n",
    "    \n",
    "    @property\n",
    "    def b(self):\n",
    "        return 4\n",
    "\n",
    "c = A()\n",
    "print(c.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
